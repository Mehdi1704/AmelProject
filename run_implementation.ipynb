{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from helpers_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_cleaned_csv_data(\"dataset\", sub_sample=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing gamma: 0.001\n",
      "Current iteration=0, loss=0.4725981665543393\n",
      "Current iteration=100, loss=0.15143367794530063\n",
      "Current iteration=200, loss=0.14740982820692666\n",
      "Current iteration=300, loss=0.14504751612216937\n",
      "Current iteration=400, loss=0.14353656330365666\n",
      "Current iteration=500, loss=0.14249765162213124\n",
      "Current iteration=600, loss=0.1417322417086159\n",
      "Current iteration=700, loss=0.1411342887544156\n",
      "Current iteration=800, loss=0.14064549769620782\n",
      "Current iteration=900, loss=0.14023255044107097\n",
      "Gamma: 0.001, Best Threshold: -0.5920280549360802, F1 Score: 0.38206470667203657\n",
      "Testing gamma: 0.005\n",
      "Current iteration=0, loss=0.37436983598483686\n",
      "Current iteration=100, loss=0.14244954571221327\n",
      "Current iteration=200, loss=0.13985786968584088\n",
      "Current iteration=300, loss=0.1385871011683183\n",
      "Current iteration=400, loss=0.13778058231562196\n",
      "Current iteration=500, loss=0.13721341385677008\n",
      "Current iteration=600, loss=0.13678716133870586\n",
      "Current iteration=700, loss=0.13645124746421297\n",
      "Current iteration=800, loss=0.13617697455648614\n",
      "Current iteration=900, loss=0.1359468542520861\n",
      "Gamma: 0.005, Best Threshold: -0.5730878040606386, F1 Score: 0.40665064102564097\n",
      "Testing gamma: 0.01\n",
      "Current iteration=0, loss=0.2771871800025262\n",
      "Current iteration=100, loss=0.13983607420096908\n",
      "Current iteration=200, loss=0.13777164597567398\n",
      "Current iteration=300, loss=0.13678208660170768\n",
      "Current iteration=400, loss=0.1361736048470805\n",
      "Current iteration=500, loss=0.13574719533259838\n",
      "Current iteration=600, loss=0.13542442522262432\n",
      "Current iteration=700, loss=0.13516857487070075\n",
      "Current iteration=800, loss=0.13496008767181894\n",
      "Current iteration=900, loss=0.13478728462230952\n",
      "Gamma: 0.01, Best Threshold: -0.5899545505680638, F1 Score: 0.4070673168260402\n",
      "Testing gamma: 0.015\n",
      "Current iteration=0, loss=0.2084520320530683\n",
      "Current iteration=100, loss=0.13856103728487004\n",
      "Current iteration=200, loss=0.13677702789343468\n",
      "Current iteration=300, loss=0.13594115281591923\n",
      "Current iteration=400, loss=0.13542250798207145\n",
      "Current iteration=500, loss=0.135057845840651\n",
      "Current iteration=600, loss=0.13478618303436077\n",
      "Current iteration=700, loss=0.13457791999603969\n",
      "Current iteration=800, loss=0.13441562358778317\n",
      "Current iteration=900, loss=0.13428773508715597\n",
      "Gamma: 0.015, Best Threshold: -0.5745361112419721, F1 Score: 0.40823622881355937\n",
      "Testing gamma: 0.02\n",
      "Current iteration=0, loss=0.16816439213646314\n",
      "Current iteration=100, loss=0.1377538898859698\n",
      "Current iteration=200, loss=0.1361668898054392\n",
      "Current iteration=300, loss=0.1354205936517623\n",
      "Current iteration=400, loss=0.1349574907410779\n",
      "Current iteration=500, loss=0.13464058610697513\n",
      "Current iteration=600, loss=0.13441491758042082\n",
      "Current iteration=700, loss=0.1342507307935665\n",
      "Current iteration=800, loss=0.13412943662933408\n",
      "Current iteration=900, loss=0.13403865816038077\n",
      "Gamma: 0.02, Best Threshold: -0.5877618618259199, F1 Score: 0.407431133888533\n",
      "Best Gamma: 0.015\n",
      "Best Threshold: -0.5745361112419721\n",
      "Final Accuracy: 0.8638060554345011\n",
      "Final F1 Score: 0.40823622881355937\n"
     ]
    }
   ],
   "source": [
    "# Define a range of gamma values to test\n",
    "gamma_values = [0.001, 0.005, 0.01, 0.015, 0.02]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_gamma = None\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "best_w = None\n",
    "\n",
    "# Loop over gamma values\n",
    "for gamma in gamma_values:\n",
    "    print(f\"Testing gamma: {gamma}\")\n",
    "    # Initialize weights\n",
    "    initial_w = np.zeros(X_train.shape[1])\n",
    "    # Train the model\n",
    "    w, loss = mean_squared_error_gd(y_train, X_train, initial_w, max_iters=1000, gamma=gamma)\n",
    "\n",
    "    # Compute predicted scores on the validation set\n",
    "    y_scores = X_test @ w\n",
    "\n",
    "    # Optimize threshold for the current gamma\n",
    "    threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "\n",
    "    print(f\"Gamma: {gamma}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "\n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_gamma = gamma\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = X_test @ best_w\n",
    "y_prediction = np.where(y_scores >= best_threshold, 1, -1)\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score(y_test, y_prediction)\n",
    "\n",
    "print(\"Best Gamma:\", best_gamma)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing gamma: 0.0015\n",
      "Current iteration=0, loss=0.44463934577221786\n",
      "Current iteration=100, loss=0.1536417498581622\n",
      "Current iteration=200, loss=0.15270002477886047\n",
      "Current iteration=300, loss=0.1467742804091567\n",
      "Current iteration=400, loss=0.16052972080716785\n",
      "Current iteration=500, loss=0.14382174344569126\n",
      "Current iteration=600, loss=0.14149067332226395\n",
      "Current iteration=700, loss=0.1443152339632158\n",
      "Current iteration=800, loss=0.1410103203473426\n",
      "Current iteration=900, loss=0.14082586486096027\n",
      "Current iteration=1000, loss=0.14003749838646493\n",
      "Current iteration=1100, loss=0.1426118654502608\n",
      "Current iteration=1200, loss=0.21702321732243424\n",
      "Current iteration=1300, loss=0.14106596139084612\n",
      "Current iteration=1400, loss=0.1420982360285399\n",
      "Current iteration=1500, loss=0.14255688163109942\n",
      "Current iteration=1600, loss=0.14528033315385386\n",
      "Current iteration=1700, loss=0.14228360961855335\n",
      "Current iteration=1800, loss=0.1409587822669644\n",
      "Current iteration=1900, loss=0.14223409749811566\n",
      "Current iteration=2000, loss=0.1402866667343303\n",
      "Current iteration=2100, loss=0.1397691484023402\n",
      "Current iteration=2200, loss=0.14672183111745557\n",
      "Current iteration=2300, loss=0.1441060990313682\n",
      "Current iteration=2400, loss=0.14155305372976326\n",
      "Current iteration=2500, loss=0.13955551894878981\n",
      "Current iteration=2600, loss=0.1470914568541284\n",
      "Current iteration=2700, loss=0.13958187075898418\n",
      "Current iteration=2800, loss=0.14226903009166195\n",
      "Current iteration=2900, loss=0.14333854124266493\n",
      "Gamma: 0.0015, Best Threshold: -0.3614449773703784, F1 Score: 0.3957552175451008\n",
      "Best Gamma: 0.0015\n",
      "Best Threshold: -0.3614449773703784\n",
      "Final Accuracy: 0.8698553948832035\n",
      "Final F1 Score: 0.3957552175451008\n"
     ]
    }
   ],
   "source": [
    "# Define a range of gamma values to test\n",
    "\n",
    "gamma_values = [0.0015]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_gamma = None\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "best_w = None\n",
    "\n",
    "# Loop over gamma values\n",
    "for gamma in gamma_values:\n",
    "    print(f\"Testing gamma: {gamma}\")\n",
    "    # Initialize weights\n",
    "    initial_w = np.zeros(X_train.shape[1])\n",
    "    # Train the model\n",
    "    w, loss = mean_squared_error_sgd(y_train, X_train, initial_w, max_iters=3000, gamma=gamma)\n",
    "\n",
    "    # Compute predicted scores on the validation set\n",
    "    y_scores = X_test @ w\n",
    "\n",
    "    # Optimize threshold for the current gamma\n",
    "    threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "\n",
    "    print(f\"Gamma: {gamma}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "\n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_gamma = gamma\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = X_test @ best_w\n",
    "y_prediction = np.where(y_scores >= best_threshold, 1, -1)\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score(y_test, y_prediction)\n",
    "\n",
    "print(\"Best Gamma:\", best_gamma)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: -0.5655146528668263\n",
      "Final Accuracy: 0.8670821460679293\n",
      "Final F1 Score: 0.4072035338090384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poseidon\\Desktop\\AmelProject\\implementations.py:105: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w=np.linalg.lstsq(A,b)[0]\n"
     ]
    }
   ],
   "source": [
    "w, loss = least_squares(y_train, X_train)\n",
    "\n",
    "y_scores = X_test @ w\n",
    "\n",
    "# Optimize threshold for the current gamma\n",
    "threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = X_test @ w\n",
    "y_prediction = np.where(y_scores >= threshold, 1, -1)\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score(y_test, y_prediction)\n",
    "\n",
    "print(\"Best Threshold:\", threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lambda: 0.001\n",
      "Lambda: 0.001, Best Threshold: -0.585168969082059, F1 Score: 0.4062782586229169\n",
      "Testing lambda: 0.005\n",
      "Lambda: 0.005, Best Threshold: -0.5884517174049512, F1 Score: 0.4075311656599409\n",
      "Testing lambda: 0.01\n",
      "Lambda: 0.01, Best Threshold: -0.5876336244217959, F1 Score: 0.4086076928032988\n",
      "Testing lambda: 0.015\n",
      "Lambda: 0.015, Best Threshold: -0.5864565574752844, F1 Score: 0.40940597266308215\n",
      "Testing lambda: 0.02\n",
      "Lambda: 0.02, Best Threshold: -0.5836048982172071, F1 Score: 0.40936131267568804\n",
      "Best Lambda: 0.015\n",
      "Best Threshold: -0.5864565574752844\n",
      "Final F1 Score: 0.40940597266308215\n",
      "Final Accuracy: 0.8610785195117863\n"
     ]
    }
   ],
   "source": [
    "# Define a range of lambda values to test\n",
    "lambda_values = [0.001, 0.005, 0.01 , 0.015, 0.02]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_lambda = None\n",
    "best_threshold = None\n",
    "best_f1 = -1\n",
    "best_w = None\n",
    "\n",
    "# Loop over lambda values\n",
    "for lambda_ in lambda_values:\n",
    "    print(f\"Testing lambda: {lambda_}\")\n",
    "    # Train the model\n",
    "    w, loss = ridge_regression(y_train, X_train, lambda_)\n",
    "    \n",
    "    # Compute predicted scores on the test set\n",
    "    y_scores = X_test @ w  # Continuous scores\n",
    "    \n",
    "    # Optimize threshold for the current lambda\n",
    "    threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "    \n",
    "    print(f\"Lambda: {lambda_}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "    \n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_lambda = lambda_\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best lambda and threshold, make predictions on the test set\n",
    "y_scores = X_test @ best_w\n",
    "y_pred = np.where(y_scores >= best_threshold, 1, -1)\n",
    "\n",
    "# Compute final F1 score\n",
    "final_f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Lambda:\", best_lambda)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n",
    "print(\"Final Accuracy:\", accuracy(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing gamma: 0.001\n",
      "Current iteration=0, loss=0.686190043604647\n",
      "Current iteration=100, loss=0.3813197240800137\n",
      "Current iteration=200, loss=0.3189964180323503\n",
      "Current iteration=300, loss=0.29846338414482615\n",
      "Current iteration=400, loss=0.2893554646429806\n",
      "Gamma: 0.001, Best Threshold: 0.13131313131313133, F1 Score: 0.300346172866641\n",
      "Testing gamma: 0.005\n",
      "Current iteration=0, loss=0.6590724115869734\n",
      "Current iteration=100, loss=0.2840282244249369\n",
      "Current iteration=200, loss=0.27266893710878976\n",
      "Current iteration=300, loss=0.2656514142742886\n",
      "Current iteration=400, loss=0.26025352165742227\n",
      "Gamma: 0.005, Best Threshold: 0.13131313131313133, F1 Score: 0.35930349369349257\n",
      "Testing gamma: 0.01\n",
      "Current iteration=0, loss=0.6267717812660576\n",
      "Current iteration=100, loss=0.2725586086709883\n",
      "Current iteration=200, loss=0.2601867214715242\n",
      "Current iteration=300, loss=0.2525972510851191\n",
      "Current iteration=400, loss=0.2476461953681938\n",
      "Gamma: 0.01, Best Threshold: 0.15151515151515152, F1 Score: 0.3740845735884715\n",
      "Testing gamma: 0.015\n",
      "Current iteration=0, loss=0.5962354921438835\n",
      "Current iteration=100, loss=0.26548573073482135\n",
      "Current iteration=200, loss=0.2525527664576376\n",
      "Current iteration=300, loss=0.24576149853975424\n",
      "Current iteration=400, loss=0.24169592586608396\n",
      "Gamma: 0.015, Best Threshold: 0.16161616161616163, F1 Score: 0.3829373518867351\n",
      "Testing gamma: 0.02\n",
      "Current iteration=0, loss=0.5674473794964167\n",
      "Current iteration=100, loss=0.2600533690594748\n",
      "Current iteration=200, loss=0.2475845839577034\n",
      "Current iteration=300, loss=0.24167922693260446\n",
      "Current iteration=400, loss=0.23825718325509443\n",
      "Gamma: 0.02, Best Threshold: 0.17171717171717174, F1 Score: 0.3887274105901681\n",
      "Best Gamma: 0.02\n",
      "Best Threshold: 0.17171717171717174\n",
      "Final Accuracy: 0.852591159126579\n",
      "Final F1 Score: 0.3887274105901681\n"
     ]
    }
   ],
   "source": [
    "# Convert y_train and y_test to binary labels (0 and 1)\n",
    "y_train_binary = (y_train + 1) // 2\n",
    "y_test_binary = (y_test + 1) // 2\n",
    "\n",
    "# Define a range of gamma values to test\n",
    "gamma_values = [0.001, 0.005, 0.01, 0.015, 0.02]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_gamma = None\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "best_w = None\n",
    "\n",
    "# Loop over gamma values\n",
    "for gamma in gamma_values:\n",
    "    print(f\"Testing gamma: {gamma}\")\n",
    "    # Initialize weights\n",
    "    initial_w = np.zeros(X_train.shape[1])\n",
    "    # Train the model\n",
    "    w, loss = logistic_regression(y_train_binary, X_train, initial_w, max_iters=500, gamma=gamma)\n",
    "    \n",
    "    # Compute predicted probabilities on the validation set\n",
    "    y_scores = sigmoid(X_test @ w)\n",
    "    \n",
    "    # Optimize threshold for the current gamma\n",
    "    threshold, f1 = optimize_threshold_logistic(y_test_binary, y_scores)\n",
    "    \n",
    "    print(f\"Gamma: {gamma}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "    \n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_gamma = gamma\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = sigmoid(X_test @ best_w)\n",
    "y_prediction_binary = np.where(y_scores >= best_threshold, 1, 0)\n",
    "y_prediction = y_prediction_binary * 2 - 1  # Convert back to -1 and 1\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score_logistic(y_test_binary, y_prediction_binary)\n",
    "\n",
    "print(\"Best Gamma:\", best_gamma)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
