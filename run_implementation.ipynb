{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from helpers_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_cleaned_csv_data(\"dataset\", sub_sample=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing gamma: 0.001\n",
      "Current iteration=0, loss=0.4725981665543393\n",
      "Current iteration=100, loss=0.15143367794530063\n",
      "Current iteration=200, loss=0.14740982820692666\n",
      "Current iteration=300, loss=0.14504751612216937\n",
      "Current iteration=400, loss=0.14353656330365666\n",
      "Current iteration=500, loss=0.14249765162213124\n",
      "Current iteration=600, loss=0.1417322417086159\n",
      "Current iteration=700, loss=0.1411342887544156\n",
      "Current iteration=800, loss=0.14064549769620782\n",
      "Current iteration=900, loss=0.14023255044107097\n",
      "Gamma: 0.001, Best Threshold: -0.5920280549360802, F1 Score: 0.38206470667203657\n",
      "Testing gamma: 0.005\n",
      "Current iteration=0, loss=0.37436983598483686\n",
      "Current iteration=100, loss=0.14244954571221327\n",
      "Current iteration=200, loss=0.13985786968584088\n",
      "Current iteration=300, loss=0.1385871011683183\n",
      "Current iteration=400, loss=0.13778058231562196\n",
      "Current iteration=500, loss=0.13721341385677008\n",
      "Current iteration=600, loss=0.13678716133870586\n",
      "Current iteration=700, loss=0.13645124746421297\n",
      "Current iteration=800, loss=0.13617697455648614\n",
      "Current iteration=900, loss=0.1359468542520861\n",
      "Gamma: 0.005, Best Threshold: -0.5730878040606386, F1 Score: 0.40665064102564097\n",
      "Testing gamma: 0.01\n",
      "Current iteration=0, loss=0.2771871800025262\n",
      "Current iteration=100, loss=0.13983607420096908\n",
      "Current iteration=200, loss=0.13777164597567398\n",
      "Current iteration=300, loss=0.13678208660170768\n",
      "Current iteration=400, loss=0.1361736048470805\n",
      "Current iteration=500, loss=0.13574719533259838\n",
      "Current iteration=600, loss=0.13542442522262432\n",
      "Current iteration=700, loss=0.13516857487070075\n",
      "Current iteration=800, loss=0.13496008767181894\n",
      "Current iteration=900, loss=0.13478728462230952\n",
      "Gamma: 0.01, Best Threshold: -0.5899545505680638, F1 Score: 0.4070673168260402\n",
      "Testing gamma: 0.015\n",
      "Current iteration=0, loss=0.2084520320530683\n",
      "Current iteration=100, loss=0.13856103728487004\n",
      "Current iteration=200, loss=0.13677702789343468\n",
      "Current iteration=300, loss=0.13594115281591923\n",
      "Current iteration=400, loss=0.13542250798207145\n",
      "Current iteration=500, loss=0.135057845840651\n",
      "Current iteration=600, loss=0.13478618303436077\n",
      "Current iteration=700, loss=0.13457791999603969\n",
      "Current iteration=800, loss=0.13441562358778317\n",
      "Current iteration=900, loss=0.13428773508715597\n",
      "Gamma: 0.015, Best Threshold: -0.5745361112419721, F1 Score: 0.40823622881355937\n",
      "Testing gamma: 0.02\n",
      "Current iteration=0, loss=0.16816439213646314\n",
      "Current iteration=100, loss=0.1377538898859698\n",
      "Current iteration=200, loss=0.1361668898054392\n",
      "Current iteration=300, loss=0.1354205936517623\n",
      "Current iteration=400, loss=0.1349574907410779\n",
      "Current iteration=500, loss=0.13464058610697513\n",
      "Current iteration=600, loss=0.13441491758042082\n",
      "Current iteration=700, loss=0.1342507307935665\n",
      "Current iteration=800, loss=0.13412943662933408\n",
      "Current iteration=900, loss=0.13403865816038077\n",
      "Gamma: 0.02, Best Threshold: -0.5877618618259199, F1 Score: 0.407431133888533\n",
      "Best Gamma: 0.015\n",
      "Best Threshold: -0.5745361112419721\n",
      "Final Accuracy: 0.8638060554345011\n",
      "Final F1 Score: 0.40823622881355937\n"
     ]
    }
   ],
   "source": [
    "# Define a range of gamma values to test\n",
    "gamma_values = [0.001, 0.005, 0.01, 0.015, 0.02]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_gamma = None\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "best_w = None\n",
    "\n",
    "# Loop over gamma values\n",
    "for gamma in gamma_values:\n",
    "    print(f\"Testing gamma: {gamma}\")\n",
    "    # Initialize weights\n",
    "    initial_w = np.zeros(X_train.shape[1])\n",
    "    # Train the model\n",
    "    w, loss = mean_squared_error_gd(y_train, X_train, initial_w, max_iters=1000, gamma=gamma)\n",
    "\n",
    "    # Compute predicted scores on the validation set\n",
    "    y_scores = X_test @ w\n",
    "\n",
    "    # Optimize threshold for the current gamma\n",
    "    threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "\n",
    "    print(f\"Gamma: {gamma}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "\n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_gamma = gamma\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = X_test @ best_w\n",
    "y_prediction = np.where(y_scores >= best_threshold, 1, -1)\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score(y_test, y_prediction)\n",
    "\n",
    "print(\"Best Gamma:\", best_gamma)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing gamma: 0.0015\n",
      "Current iteration=0, loss=0.44463934577221786\n",
      "Current iteration=100, loss=0.1536417498581622\n",
      "Current iteration=200, loss=0.15270002477886047\n",
      "Current iteration=300, loss=0.1467742804091567\n",
      "Current iteration=400, loss=0.16052972080716785\n",
      "Current iteration=500, loss=0.14382174344569126\n",
      "Current iteration=600, loss=0.14149067332226395\n",
      "Current iteration=700, loss=0.1443152339632158\n",
      "Current iteration=800, loss=0.1410103203473426\n",
      "Current iteration=900, loss=0.14082586486096027\n",
      "Current iteration=1000, loss=0.14003749838646493\n",
      "Current iteration=1100, loss=0.1426118654502608\n",
      "Current iteration=1200, loss=0.21702321732243424\n",
      "Current iteration=1300, loss=0.14106596139084612\n",
      "Current iteration=1400, loss=0.1420982360285399\n",
      "Current iteration=1500, loss=0.14255688163109942\n",
      "Current iteration=1600, loss=0.14528033315385386\n",
      "Current iteration=1700, loss=0.14228360961855335\n",
      "Current iteration=1800, loss=0.1409587822669644\n",
      "Current iteration=1900, loss=0.14223409749811566\n",
      "Current iteration=2000, loss=0.1402866667343303\n",
      "Current iteration=2100, loss=0.1397691484023402\n",
      "Current iteration=2200, loss=0.14672183111745557\n",
      "Current iteration=2300, loss=0.1441060990313682\n",
      "Current iteration=2400, loss=0.14155305372976326\n",
      "Current iteration=2500, loss=0.13955551894878981\n",
      "Current iteration=2600, loss=0.1470914568541284\n",
      "Current iteration=2700, loss=0.13958187075898418\n",
      "Current iteration=2800, loss=0.14226903009166195\n",
      "Current iteration=2900, loss=0.14333854124266493\n",
      "Gamma: 0.0015, Best Threshold: -0.3614449773703784, F1 Score: 0.3957552175451008\n",
      "Best Gamma: 0.0015\n",
      "Best Threshold: -0.3614449773703784\n",
      "Final Accuracy: 0.8698553948832035\n",
      "Final F1 Score: 0.3957552175451008\n"
     ]
    }
   ],
   "source": [
    "# Define a range of gamma values to test\n",
    "\n",
    "gamma_values = [0.0015]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_gamma = None\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "best_w = None\n",
    "\n",
    "# Loop over gamma values\n",
    "for gamma in gamma_values:\n",
    "    print(f\"Testing gamma: {gamma}\")\n",
    "    # Initialize weights\n",
    "    initial_w = np.zeros(X_train.shape[1])\n",
    "    # Train the model\n",
    "    w, loss = mean_squared_error_sgd(y_train, X_train, initial_w, max_iters=3000, gamma=gamma)\n",
    "\n",
    "    # Compute predicted scores on the validation set\n",
    "    y_scores = X_test @ w\n",
    "\n",
    "    # Optimize threshold for the current gamma\n",
    "    threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "\n",
    "    print(f\"Gamma: {gamma}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "\n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_gamma = gamma\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = X_test @ best_w\n",
    "y_prediction = np.where(y_scores >= best_threshold, 1, -1)\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score(y_test, y_prediction)\n",
    "\n",
    "print(\"Best Gamma:\", best_gamma)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: -0.5655146528668263\n",
      "Final Accuracy: 0.8670821460679293\n",
      "Final F1 Score: 0.4072035338090384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\poseidon\\Desktop\\AmelProject\\implementations.py:105: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  w=np.linalg.lstsq(A,b)[0]\n"
     ]
    }
   ],
   "source": [
    "w, loss = least_squares(y_train, X_train)\n",
    "\n",
    "y_scores = X_test @ w\n",
    "\n",
    "# Optimize threshold for the current gamma\n",
    "threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = X_test @ w\n",
    "y_prediction = np.where(y_scores >= threshold, 1, -1)\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score(y_test, y_prediction)\n",
    "\n",
    "print(\"Best Threshold:\", threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lambda: 0.001\n",
      "Lambda: 0.001, Best Threshold: -0.585168969082059, F1 Score: 0.4062782586229169\n",
      "Testing lambda: 0.005\n",
      "Lambda: 0.005, Best Threshold: -0.5884517174049512, F1 Score: 0.4075311656599409\n",
      "Testing lambda: 0.01\n",
      "Lambda: 0.01, Best Threshold: -0.5876336244217959, F1 Score: 0.4086076928032988\n",
      "Testing lambda: 0.015\n",
      "Lambda: 0.015, Best Threshold: -0.5864565574752844, F1 Score: 0.40940597266308215\n",
      "Testing lambda: 0.02\n",
      "Lambda: 0.02, Best Threshold: -0.5836048982172071, F1 Score: 0.40936131267568804\n",
      "Best Lambda: 0.015\n",
      "Best Threshold: -0.5864565574752844\n",
      "Final F1 Score: 0.40940597266308215\n",
      "Final Accuracy: 0.8610785195117863\n"
     ]
    }
   ],
   "source": [
    "# Define a range of lambda values to test\n",
    "lambda_values = [0.001, 0.005, 0.01 , 0.015, 0.02]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_lambda = None\n",
    "best_threshold = None\n",
    "best_f1 = -1\n",
    "best_w = None\n",
    "\n",
    "# Loop over lambda values\n",
    "for lambda_ in lambda_values:\n",
    "    print(f\"Testing lambda: {lambda_}\")\n",
    "    # Train the model\n",
    "    w, loss = ridge_regression(y_train, X_train, lambda_)\n",
    "    \n",
    "    # Compute predicted scores on the test set\n",
    "    y_scores = X_test @ w  # Continuous scores\n",
    "    \n",
    "    # Optimize threshold for the current lambda\n",
    "    threshold, f1 = optimize_threshold(y_test, y_scores)\n",
    "    \n",
    "    print(f\"Lambda: {lambda_}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "    \n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_lambda = lambda_\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best lambda and threshold, make predictions on the test set\n",
    "y_scores = X_test @ best_w\n",
    "y_pred = np.where(y_scores >= best_threshold, 1, -1)\n",
    "\n",
    "# Compute final F1 score\n",
    "final_f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Lambda:\", best_lambda)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n",
    "print(\"Final Accuracy:\", accuracy(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing gamma: 0.001\n",
      "Current iteration=0, loss=0.686190043604647\n",
      "Current iteration=100, loss=0.3813197240800137\n",
      "Current iteration=200, loss=0.3189964180323503\n",
      "Current iteration=300, loss=0.29846338414482615\n",
      "Current iteration=400, loss=0.2893554646429806\n",
      "Gamma: 0.001, Best Threshold: 0.13131313131313133, F1 Score: 0.300346172866641\n",
      "Testing gamma: 0.005\n",
      "Current iteration=0, loss=0.6590724115869734\n",
      "Current iteration=100, loss=0.2840282244249369\n",
      "Current iteration=200, loss=0.27266893710878976\n",
      "Current iteration=300, loss=0.2656514142742886\n",
      "Current iteration=400, loss=0.26025352165742227\n",
      "Gamma: 0.005, Best Threshold: 0.13131313131313133, F1 Score: 0.35930349369349257\n",
      "Testing gamma: 0.01\n",
      "Current iteration=0, loss=0.6267717812660576\n",
      "Current iteration=100, loss=0.2725586086709883\n",
      "Current iteration=200, loss=0.2601867214715242\n",
      "Current iteration=300, loss=0.2525972510851191\n",
      "Current iteration=400, loss=0.2476461953681938\n",
      "Gamma: 0.01, Best Threshold: 0.15151515151515152, F1 Score: 0.3740845735884715\n",
      "Testing gamma: 0.015\n",
      "Current iteration=0, loss=0.5962354921438835\n",
      "Current iteration=100, loss=0.26548573073482135\n",
      "Current iteration=200, loss=0.2525527664576376\n",
      "Current iteration=300, loss=0.24576149853975424\n",
      "Current iteration=400, loss=0.24169592586608396\n",
      "Gamma: 0.015, Best Threshold: 0.16161616161616163, F1 Score: 0.3829373518867351\n",
      "Testing gamma: 0.02\n",
      "Current iteration=0, loss=0.5674473794964167\n",
      "Current iteration=100, loss=0.2600533690594748\n",
      "Current iteration=200, loss=0.2475845839577034\n",
      "Current iteration=300, loss=0.24167922693260446\n",
      "Current iteration=400, loss=0.23825718325509443\n",
      "Gamma: 0.02, Best Threshold: 0.17171717171717174, F1 Score: 0.3887274105901681\n",
      "Best Gamma: 0.02\n",
      "Best Threshold: 0.17171717171717174\n",
      "Final Accuracy: 0.852591159126579\n",
      "Final F1 Score: 0.3887274105901681\n"
     ]
    }
   ],
   "source": [
    "# Convert y_train and y_test to binary labels (0 and 1)\n",
    "y_train_binary = (y_train + 1) // 2\n",
    "y_test_binary = (y_test + 1) // 2\n",
    "\n",
    "# Define a range of gamma values to test\n",
    "gamma_values = [0.001, 0.005, 0.01, 0.015, 0.02]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_gamma = None\n",
    "best_threshold = None\n",
    "best_f1 = 0\n",
    "best_w = None\n",
    "\n",
    "# Loop over gamma values\n",
    "for gamma in gamma_values:\n",
    "    print(f\"Testing gamma: {gamma}\")\n",
    "    # Initialize weights\n",
    "    initial_w = np.zeros(X_train.shape[1])\n",
    "    # Train the model\n",
    "    w, loss = logistic_regression(y_train_binary, X_train, initial_w, max_iters=500, gamma=gamma)\n",
    "    \n",
    "    # Compute predicted probabilities on the validation set\n",
    "    y_scores = sigmoid(X_test @ w)\n",
    "    \n",
    "    # Optimize threshold for the current gamma\n",
    "    threshold, f1 = optimize_threshold_logistic(y_test_binary, y_scores)\n",
    "    \n",
    "    print(f\"Gamma: {gamma}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "    \n",
    "    # Update best parameters if current F1 is better\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_gamma = gamma\n",
    "        best_threshold = threshold\n",
    "        best_w = w.copy()\n",
    "\n",
    "# After finding the best gamma and threshold, make predictions on the test set\n",
    "y_scores = sigmoid(X_test @ best_w)\n",
    "y_prediction_binary = np.where(y_scores >= best_threshold, 1, 0)\n",
    "y_prediction = y_prediction_binary * 2 - 1  # Convert back to -1 and 1\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score_logistic(y_test_binary, y_prediction_binary)\n",
    "\n",
    "print(\"Best Gamma:\", best_gamma)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing gamma: 0.001, lambda: 0.001\n",
      "Current iteration=0, loss=0.6861900505973428 (with regularization)\n",
      "Current iteration=100, loss=0.3813652827469973 (with regularization)\n",
      "Current iteration=200, loss=0.3190814635104565 (with regularization)\n",
      "Current iteration=300, loss=0.29857336324453326 (with regularization)\n",
      "Current iteration=400, loss=0.28948213032139886 (with regularization)\n",
      "Gamma: 0.001, Lambda: 0.001, Best Threshold: 0.13131313131313133, F1 Score: 0.30049936892937495\n",
      "Testing gamma: 0.001, lambda: 0.01\n",
      "Current iteration=0, loss=0.686190113531606 (with regularization)\n",
      "Current iteration=100, loss=0.3817748277607147 (with regularization)\n",
      "Current iteration=200, loss=0.31984517940734375 (with regularization)\n",
      "Current iteration=300, loss=0.2995600534115876 (with regularization)\n",
      "Current iteration=400, loss=0.29061756457323135 (with regularization)\n",
      "Gamma: 0.001, Lambda: 0.01, Best Threshold: 0.13131313131313133, F1 Score: 0.30082751906539024\n",
      "Testing gamma: 0.001, lambda: 0.1\n",
      "Current iteration=0, loss=0.6861907428742371 (with regularization)\n",
      "Current iteration=100, loss=0.3858229236036815 (with regularization)\n",
      "Current iteration=200, loss=0.32731804159145395 (with regularization)\n",
      "Current iteration=300, loss=0.3091273754751656 (with regularization)\n",
      "Current iteration=400, loss=0.30153930962333164 (with regularization)\n",
      "Gamma: 0.001, Lambda: 0.1, Best Threshold: 0.14141414141414144, F1 Score: 0.29936827328029947\n",
      "Testing gamma: 0.001, lambda: 1\n",
      "Current iteration=0, loss=0.6861970363005485 (with regularization)\n",
      "Current iteration=100, loss=0.4219940194267886 (with regularization)\n",
      "Current iteration=200, loss=0.3884392091321855 (with regularization)\n",
      "Current iteration=300, loss=0.3821225918443734 (with regularization)\n",
      "Current iteration=400, loss=0.38055082944865776 (with regularization)\n",
      "Gamma: 0.001, Lambda: 1, Best Threshold: 0.19191919191919193, F1 Score: 0.29249641548510436\n",
      "Testing gamma: 0.001, lambda: 10\n",
      "Current iteration=0, loss=0.6862599705636627 (with regularization)\n",
      "Current iteration=100, loss=0.5769522489382518 (with regularization)\n",
      "Current iteration=200, loss=0.5766803434453918 (with regularization)\n",
      "Current iteration=300, loss=0.5766795442311596 (with regularization)\n",
      "Current iteration=400, loss=0.5766795405607593 (with regularization)\n",
      "Gamma: 0.001, Lambda: 10, Best Threshold: 0.37373737373737376, F1 Score: 0.2612030470186499\n",
      "Testing gamma: 0.005, lambda: 0.001\n",
      "Current iteration=0, loss=0.6590725864043709 (with regularization)\n",
      "Current iteration=100, loss=0.28416774776587783 (with regularization)\n",
      "Current iteration=200, loss=0.2728489505556221 (with regularization)\n",
      "Current iteration=300, loss=0.26587113920521654 (with regularization)\n",
      "Current iteration=400, loss=0.26051576495109835 (with regularization)\n",
      "Gamma: 0.005, Lambda: 0.001, Best Threshold: 0.13131313131313133, F1 Score: 0.35923737317426685\n",
      "Testing gamma: 0.005, lambda: 0.01\n",
      "Current iteration=0, loss=0.6590741597609487 (with regularization)\n",
      "Current iteration=100, loss=0.2854174370056485 (with regularization)\n",
      "Current iteration=200, loss=0.2744560866464795 (with regularization)\n",
      "Current iteration=300, loss=0.2678253267450765 (with regularization)\n",
      "Current iteration=400, loss=0.26283748513518923 (with regularization)\n",
      "Gamma: 0.005, Lambda: 0.01, Best Threshold: 0.13131313131313133, F1 Score: 0.3586000995189915\n",
      "Testing gamma: 0.005, lambda: 0.1\n",
      "Current iteration=0, loss=0.6590898933267273 (with regularization)\n",
      "Current iteration=100, loss=0.2973489264138765 (with regularization)\n",
      "Current iteration=200, loss=0.28935986359969007 (with regularization)\n",
      "Current iteration=300, loss=0.2853568673463833 (with regularization)\n",
      "Current iteration=400, loss=0.2828899388184825 (with regularization)\n",
      "Gamma: 0.005, Lambda: 0.1, Best Threshold: 0.15151515151515152, F1 Score: 0.3546522953054996\n",
      "Testing gamma: 0.005, lambda: 1\n",
      "Current iteration=0, loss=0.6592472289845128 (with regularization)\n",
      "Current iteration=100, loss=0.38000040927501255 (with regularization)\n",
      "Current iteration=200, loss=0.37953227320532557 (with regularization)\n",
      "Current iteration=300, loss=0.37949557570409476 (with regularization)\n",
      "Current iteration=400, loss=0.3794922631916593 (with regularization)\n",
      "Gamma: 0.005, Lambda: 1, Best Threshold: 0.19191919191919193, F1 Score: 0.3078735940010712\n",
      "Testing gamma: 0.005, lambda: 10\n",
      "Current iteration=0, loss=0.6608205855623683 (with regularization)\n",
      "Current iteration=100, loss=0.5766795405260814 (with regularization)\n",
      "Current iteration=200, loss=0.5766795405259255 (with regularization)\n",
      "Current iteration=300, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=400, loss=0.5766795405259254 (with regularization)\n",
      "Gamma: 0.005, Lambda: 10, Best Threshold: 0.37373737373737376, F1 Score: 0.2612030470186499\n",
      "Testing gamma: 0.01, lambda: 0.001\n",
      "Current iteration=0, loss=0.6267724805356477 (with regularization)\n",
      "Current iteration=100, loss=0.2727390744965892 (with regularization)\n",
      "Current iteration=200, loss=0.26044947583712136 (with regularization)\n",
      "Current iteration=300, loss=0.2529446043936723 (with regularization)\n",
      "Current iteration=400, loss=0.24807112932740458 (with regularization)\n",
      "Gamma: 0.01, Lambda: 0.001, Best Threshold: 0.15151515151515152, F1 Score: 0.3741287655050207\n",
      "Testing gamma: 0.01, lambda: 0.01\n",
      "Current iteration=0, loss=0.6267787739619591 (with regularization)\n",
      "Current iteration=100, loss=0.27435019406556466 (with regularization)\n",
      "Current iteration=200, loss=0.2627756241733968 (with regularization)\n",
      "Current iteration=300, loss=0.25598976632805387 (with regularization)\n",
      "Current iteration=400, loss=0.2517608103214961 (with regularization)\n",
      "Gamma: 0.01, Lambda: 0.01, Best Threshold: 0.15151515151515152, F1 Score: 0.3737081438610997\n",
      "Testing gamma: 0.01, lambda: 0.1\n",
      "Current iteration=0, loss=0.6268417082250733 (with regularization)\n",
      "Current iteration=100, loss=0.28928634337826936 (with regularization)\n",
      "Current iteration=200, loss=0.2828589986307088 (with regularization)\n",
      "Current iteration=300, loss=0.28034048719233684 (with regularization)\n",
      "Current iteration=400, loss=0.27929034806854586 (with regularization)\n",
      "Gamma: 0.01, Lambda: 0.1, Best Threshold: 0.15151515151515152, F1 Score: 0.366382603585072\n",
      "Testing gamma: 0.01, lambda: 1\n",
      "Current iteration=0, loss=0.6274710508562156 (with regularization)\n",
      "Current iteration=100, loss=0.3795300762017161 (with regularization)\n",
      "Current iteration=200, loss=0.3794922364642199 (with regularization)\n",
      "Current iteration=300, loss=0.3794919237889664 (with regularization)\n",
      "Current iteration=400, loss=0.3794919207860603 (with regularization)\n",
      "Gamma: 0.01, Lambda: 1, Best Threshold: 0.19191919191919193, F1 Score: 0.3080629617732092\n",
      "Testing gamma: 0.01, lambda: 10\n",
      "Current iteration=0, loss=0.6337644771676372 (with regularization)\n",
      "Current iteration=100, loss=0.5766795405259255 (with regularization)\n",
      "Current iteration=200, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=300, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=400, loss=0.5766795405259254 (with regularization)\n",
      "Gamma: 0.01, Lambda: 10, Best Threshold: 0.37373737373737376, F1 Score: 0.2612030470186499\n",
      "Testing gamma: 0.015, lambda: 0.001\n",
      "Current iteration=0, loss=0.5962370655004614 (with regularization)\n",
      "Current iteration=100, loss=0.2657064122994478 (with regularization)\n",
      "Current iteration=200, loss=0.2529006337424681 (with regularization)\n",
      "Current iteration=300, loss=0.2462225224022538 (with regularization)\n",
      "Current iteration=400, loss=0.24225245058449146 (with regularization)\n",
      "Gamma: 0.015, Lambda: 0.001, Best Threshold: 0.16161616161616163, F1 Score: 0.38293216630196936\n",
      "Testing gamma: 0.015, lambda: 0.01\n",
      "Current iteration=0, loss=0.596251225709662 (with regularization)\n",
      "Current iteration=100, loss=0.2676689638210125 (with regularization)\n",
      "Current iteration=200, loss=0.2559501640980284 (with regularization)\n",
      "Current iteration=300, loss=0.2502068656979721 (with regularization)\n",
      "Current iteration=400, loss=0.24699885395021862 (with regularization)\n",
      "Gamma: 0.015, Lambda: 0.01, Best Threshold: 0.16161616161616163, F1 Score: 0.38139364750350546\n",
      "Testing gamma: 0.015, lambda: 0.1\n",
      "Current iteration=0, loss=0.596392827801669 (with regularization)\n",
      "Current iteration=100, loss=0.28526398209017384 (with regularization)\n",
      "Current iteration=200, loss=0.28032663161279037 (with regularization)\n",
      "Current iteration=300, loss=0.2790078440337466 (with regularization)\n",
      "Current iteration=400, loss=0.2786016905560226 (with regularization)\n",
      "Gamma: 0.015, Lambda: 0.1, Best Threshold: 0.15151515151515152, F1 Score: 0.3705282562359583\n",
      "Testing gamma: 0.015, lambda: 1\n",
      "Current iteration=0, loss=0.5978088487217389 (with regularization)\n",
      "Current iteration=100, loss=0.37949510113853524 (with regularization)\n",
      "Current iteration=200, loss=0.37949192348919625 (with regularization)\n",
      "Current iteration=300, loss=0.3794919207554063 (with regularization)\n",
      "Current iteration=400, loss=0.37949192075211646 (with regularization)\n",
      "Gamma: 0.015, Lambda: 1, Best Threshold: 0.19191919191919193, F1 Score: 0.3080629617732092\n",
      "Testing gamma: 0.015, lambda: 10\n",
      "Current iteration=0, loss=0.6119690579224376 (with regularization)\n",
      "Current iteration=100, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=200, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=300, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=400, loss=0.5766795405259254 (with regularization)\n",
      "Gamma: 0.015, Lambda: 10, Best Threshold: 0.37373737373737376, F1 Score: 0.2612030470186499\n",
      "Testing gamma: 0.02, lambda: 0.001\n",
      "Current iteration=0, loss=0.5674501765747773 (with regularization)\n",
      "Current iteration=100, loss=0.2603171492270156 (with regularization)\n",
      "Current iteration=200, loss=0.24801047461058848 (with regularization)\n",
      "Current iteration=300, loss=0.2422361447112535 (with regularization)\n",
      "Current iteration=400, loss=0.23892079617538423 (with regularization)\n",
      "Gamma: 0.02, Lambda: 0.001, Best Threshold: 0.17171717171717174, F1 Score: 0.38831636846431056\n",
      "Testing gamma: 0.02, lambda: 0.01\n",
      "Current iteration=0, loss=0.5674753502800229 (with regularization)\n",
      "Current iteration=100, loss=0.26265218425503667 (with regularization)\n",
      "Current iteration=200, loss=0.2517081255859354 (with regularization)\n",
      "Current iteration=300, loss=0.24698569055762484 (with regularization)\n",
      "Current iteration=400, loss=0.24448865117627475 (with regularization)\n",
      "Gamma: 0.02, Lambda: 0.01, Best Threshold: 0.17171717171717174, F1 Score: 0.3869282711173398\n",
      "Testing gamma: 0.02, lambda: 0.1\n",
      "Current iteration=0, loss=0.5677270873324799 (with regularization)\n",
      "Current iteration=100, loss=0.28279752316120405 (with regularization)\n",
      "Current iteration=200, loss=0.2792774898312297 (with regularization)\n",
      "Current iteration=300, loss=0.27860010863806867 (with regularization)\n",
      "Current iteration=400, loss=0.2784348294580473 (with regularization)\n",
      "Gamma: 0.02, Lambda: 0.1, Best Threshold: 0.15151515151515152, F1 Score: 0.3722531413161972\n",
      "Testing gamma: 0.02, lambda: 1\n",
      "Current iteration=0, loss=0.5702444578570485 (with regularization)\n",
      "Current iteration=100, loss=0.37949218822504466 (with regularization)\n",
      "Current iteration=200, loss=0.3794919207786219 (with regularization)\n",
      "Current iteration=300, loss=0.3794919207521158 (with regularization)\n",
      "Current iteration=400, loss=0.3794919207521116 (with regularization)\n",
      "Gamma: 0.02, Lambda: 1, Best Threshold: 0.19191919191919193, F1 Score: 0.3080629617732092\n",
      "Testing gamma: 0.02, lambda: 10\n",
      "Current iteration=0, loss=0.5954181631027351 (with regularization)\n",
      "Current iteration=100, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=200, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=300, loss=0.5766795405259254 (with regularization)\n",
      "Current iteration=400, loss=0.5766795405259254 (with regularization)\n",
      "Gamma: 0.02, Lambda: 10, Best Threshold: 0.37373737373737376, F1 Score: 0.2612030470186499\n",
      "Best Gamma: 0.02\n",
      "Best Lambda: 0.001\n",
      "Best Threshold: 0.17171717171717174\n",
      "Final Accuracy: 0.8525759214957258\n",
      "Final F1 Score: 0.38831636846431056\n"
     ]
    }
   ],
   "source": [
    "# Convert y_train and y_test to binary labels (0 and 1)\n",
    "y_train_binary = (y_train + 1) // 2\n",
    "y_test_binary = (y_test + 1) // 2\n",
    "\n",
    "# Define a range of gamma and lambda values to test\n",
    "gamma_values = [0.001, 0.005, 0.01, 0.015, 0.02]\n",
    "lambda_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# Initialize variables to store the best parameters\n",
    "best_gamma = None\n",
    "best_lambda = None\n",
    "best_threshold = None\n",
    "best_f1 = -1\n",
    "best_w = None\n",
    "\n",
    "# Loop over gamma and lambda values\n",
    "for gamma in gamma_values:\n",
    "    for lambda_ in lambda_values:\n",
    "        print(f\"Testing gamma: {gamma}, lambda: {lambda_}\")\n",
    "        # Initialize weights\n",
    "        initial_w = np.zeros(X_train.shape[1])\n",
    "        # Train the model\n",
    "        w, loss = reg_logistic_regression(\n",
    "            y_train_binary, X_train, lambda_, initial_w, max_iters=500, gamma=gamma\n",
    "        )\n",
    "        \n",
    "        # Compute predicted probabilities on the test set\n",
    "        y_scores = sigmoid(X_test @ w)\n",
    "        \n",
    "        # Optimize threshold for the current gamma and lambda\n",
    "        threshold, f1 = optimize_threshold_logistic(y_test_binary, y_scores)\n",
    "        \n",
    "        print(f\"Gamma: {gamma}, Lambda: {lambda_}, Best Threshold: {threshold}, F1 Score: {f1}\")\n",
    "        \n",
    "        # Update best parameters if current F1 is better\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_gamma = gamma\n",
    "            best_lambda = lambda_\n",
    "            best_threshold = threshold\n",
    "            best_w = w.copy()\n",
    "\n",
    "# After finding the best gamma, lambda, and threshold, make predictions on the test set\n",
    "y_scores = sigmoid(X_test @ best_w)\n",
    "y_prediction_binary = np.where(y_scores >= best_threshold, 1, 0)\n",
    "y_prediction = y_prediction_binary * 2 - 1  # Convert back to -1 and 1\n",
    "\n",
    "# Compute final accuracy and F1 score\n",
    "final_accuracy = accuracy(y_test, y_prediction)\n",
    "final_f1_score = f1_score_logistic(y_test_binary, y_prediction_binary)\n",
    "\n",
    "print(\"Best Gamma:\", best_gamma)\n",
    "print(\"Best Lambda:\", best_lambda)\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Final Accuracy:\", final_accuracy)\n",
    "print(\"Final F1 Score:\", final_f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
