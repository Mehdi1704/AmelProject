{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 322)\n",
      "(328135, 183)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Function to read the header\n",
    "def read_header(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "    return header\n",
    "\n",
    "# Read headers\n",
    "x_test_header = read_header('dataset/x_test.csv')\n",
    "y_train_header = read_header('dataset/y_train.csv')\n",
    "x_train_header = read_header('dataset/x_train.csv')\n",
    "\n",
    "# Load csvs x_test, y_test and x_train, skipping the header row\n",
    "x_test = np.genfromtxt('dataset/x_test.csv', delimiter=',', skip_header=1)\n",
    "y_train = np.genfromtxt('dataset/y_train.csv', delimiter=',', skip_header=1)\n",
    "x_train = np.genfromtxt('dataset/x_train.csv', delimiter=',', skip_header=1)\n",
    "x_train_cleaned = x_train.copy()\n",
    "x_test_cleaned = x_test.copy()\n",
    "\n",
    "\n",
    "columns_to_drop_by_name = [\n",
    "    \"FMONTH\", \"IDATE\", \"IMONTH\", \"DISPCODE\",\"IDAY\", \"IYEAR\", \"SEQNO\", \"_PSU\", \"LADULT\", \"CTELENUM\", \n",
    "    \"PVTRESD1\", \"COLGHOUS\", \"STATERES\", \"CELLFON3\", \"CTELNUM1\", \"CELLFON2\", \"CADULT\", \n",
    "    \"PVTRESD2\", \"CCLGHOUS\", \"CSTATE\", \"LANDLINE\", \"HHADULT\", \"NUMHHOL2\", \"NUMPHON2\", \n",
    "    \"CPDEMO1\", \"PREGNANT\", \"BLIND\", \"EXRACT11\", \"EXRACT21\", \"HIVTST6\", \"HIVTSTD3\", \n",
    "    \"PAINACT2\", \"QLMENTL2\", \"QLSTRES2\", \"QLHLTH2\", \"CAREGIV1\", \"CRGVREL1\", \"CRGVLNG1\", \n",
    "    \"CRGVHRS1\", \"CRGVPRB1\", \"CRGVPERS\", \"CRGVHOUS\", \"CRGVMST2\", \"CRGVEXPT\", \"VIDFCLT2\", \n",
    "    \"VIREDIF3\", \"VIPRFVS2\", \"VINOCRE2\", \"VIEYEXM2\", \"VIINSUR2\", \"VICTRCT4\", \"VIGLUMA2\", \n",
    "    \"VIMACDG2\", \"CIMEMLOS\", \"CDHOUSE\", \"CDASSIST\", \"CDHELP\", \"CDSOCIAL\", \"CDDISCUS\", \n",
    "    \"HOWLONG\", \"LASTPAP2\", \"HPLSTTST\", \"PROFEXAM\", \"LENGEXAM\", \"LSTBLDS3\", \"HADSGCO1\", \n",
    "    \"LASTSIG3\", \"PCPSAAD2\", \"PCPSADI1\", \"PCPSARE1\", \"PSATIME\", \"PCPSARS1\", \"PCPSADE1\", \n",
    "    \"PCDMDECN\", \"SCNTPAID\", \"SCNTWRK1\", \"SXORIENT\", \"TRNSGNDR\", \"RCSGENDR\", \"RCSRLTN2\", \n",
    "    \"CASTHDX2\", \"CASTHNO2\", \"QSTVER\", \"QSTLANG\", \"EXACTOT1\", \"EXACTOT2\", \"_STSTR\", \n",
    "    \"_STRWT\", \"_RAWRAKE\", \"_WT2RAKE\", \"_CHISPNC\", \"_CRACE1\", \"_CPRACE\", \"_CLLCPWT\", \n",
    "    \"_DUALUSE\", \"_DUALCOR\", \"_LLCPWT\", \"_PRACE1\", \"FEETCHK2\", \"PAINACT2\", \"QLMENTL2\", \n",
    "    \"QLSTRES2\", \"QLHLTH2\", \"CAREGIV1\", \"CRGVREL1\", \"CRGVLNG1\", \"CRGVHRS1\", \"CRGVPRB1\", \n",
    "    \"CRGVPERS\", \"CRGVHOUS\", \"CRGVMST2\", \"CRGVEXPT\", \"VIDFCLT2\", \"VIREDIF3\", \"VIPRFVS2\", \n",
    "    \"VINOCRE2\", \"VIEYEXM2\", \"VIINSUR2\", \"VICTRCT4\", \"VIGLUMA2\", \"VIMACDG2\", \"ASTHMAGE\", \n",
    "    \"ASATTACK\", \"ASERVIST\", \"ASDRVIST\", \"ASRCHKUP\", \"ASACTLIM\", \"ASYMPTOM\", \"ASNOSLEP\", \n",
    "    \"ASTHMED3\", \"ASINHALR\", \"HPVADVC2\", \"HPVADSHT\", \"_AGE_G\", \"HTIN4\", \"_CHLDCNT\", \n",
    "    \"_DRNKWEK\", \"FTJUDA1_\", \"FRUTDA1_\", \"BEANDAY_\", \"GRENDAY_\", \"ORNGDAY_\", \"VEGEDA1_\", \n",
    "    \"_MISFRTN\", \"_MISVEGN\", \"_FRTRESP\", \"_VEGRESP\", \"_FRT16\", \"_VEG23\", \"_FRUITEX\", \n",
    "    \"_VEGETEX\", \"PAMISS1_\", \"_PA150R2\", \"_PA300R2\", \"_PA30021\", \"_PASTRNG\", \"_PAREC1\", \n",
    "    \"_PASTAE1\", \"_LMTACT1\", \"_LMTWRK1\", \"_LMTSCL1\", \"_RFSEAT3\", \"_RACE\", \"_RACEG21\", \n",
    "    \"_RACE_G1\", \"_AGEG5YR\", \"_AGE65YR\"\n",
    "]\n",
    "\n",
    "# Convert column names to indices and combine with automatically identified columns\n",
    "columns_to_drop_by_index = []\n",
    "for i in range(x_train_cleaned.shape[1]): \n",
    "    unique_values = np.unique(x_train_cleaned[:, i][~np.isnan(x_train_cleaned[:, i])]) \n",
    "    if len(unique_values) == 1: \n",
    "        columns_to_drop_by_index.append(i)  # Append the index\n",
    "\n",
    "# Combine indices of manually specified columns and automatically detected ones\n",
    "columns_to_drop_indices = columns_to_drop_by_index + [i for i, col in enumerate(x_train_header) if col in columns_to_drop_by_name]\n",
    "\n",
    "# Drop these columns in both x_train and x_test\n",
    "x_train_cleaned = np.delete(x_train_cleaned, columns_to_drop_indices, axis=1)\n",
    "x_test_cleaned = np.delete(x_test_cleaned, columns_to_drop_indices, axis=1)\n",
    "\n",
    "# Drop the same columns from the headers\n",
    "x_train_header_cleaned = [col for i, col in enumerate(x_train_header) if i not in columns_to_drop_indices]\n",
    "x_test_header_cleaned = [col for i, col in enumerate(x_test_header) if i not in columns_to_drop_indices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 235)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the _STATE column from x_train_cleaned and x_test_cleaned\n",
    "state_column_index = x_train_header_cleaned.index(\"_STATE\")  # Get the index of the _STATE column\n",
    "state_train = x_train_cleaned[:, state_column_index]\n",
    "state_test = x_test_cleaned[:, state_column_index]\n",
    "\n",
    "# Identify unique states\n",
    "unique_states = np.unique(state_train)\n",
    "\n",
    "# Function to create dummy variables\n",
    "def create_dummy_variables(state_column, unique_states):\n",
    "    dummy_matrix = np.zeros((state_column.shape[0], unique_states.shape[0]))  # Initialize the matrix\n",
    "    \n",
    "    for i, state in enumerate(unique_states):\n",
    "        dummy_matrix[:, i] = (state_column == state).astype(int)  # Set 1 where the state matches, 0 otherwise\n",
    "    \n",
    "    return dummy_matrix\n",
    "\n",
    "# Create dummy variables for both train and test\n",
    "dummy_train = create_dummy_variables(state_train, unique_states)\n",
    "dummy_test = create_dummy_variables(state_test, unique_states)\n",
    "\n",
    "# Remove the original _STATE column from x_train_cleaned and x_test_cleaned\n",
    "x_train_cleaned = np.delete(x_train_cleaned, state_column_index, axis=1)\n",
    "x_test_cleaned = np.delete(x_test_cleaned, state_column_index, axis=1)\n",
    "\n",
    "# Append the dummy variables to the original dataset\n",
    "x_train_cleaned = np.hstack((x_train_cleaned, dummy_train))\n",
    "x_test_cleaned = np.hstack((x_test_cleaned, dummy_test))\n",
    "\n",
    "# Add dummy variable column names to the headers\n",
    "dummy_headers = [f\"STATE_{int(state)}\" for state in unique_states]  # Create dummy headers like \"STATE_1\", \"STATE_2\", etc.\n",
    "x_train_header_cleaned = [col for col in x_train_header_cleaned if col != \"_STATE\"] + dummy_headers\n",
    "x_test_header_cleaned = [col for col in x_test_header_cleaned if col != \"_STATE\"] + dummy_headers\n",
    "\n",
    "\n",
    "\n",
    "print(x_train_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 164)\n"
     ]
    }
   ],
   "source": [
    "#remove columns with more than 50% missing values from x_train_cleaned and x_test_cleaned\n",
    "missing_values_threshold = 0.5\n",
    "columns_to_drop = []\n",
    "for i in range(x_train_cleaned.shape[1]):\n",
    "    missing_values = np.isnan(x_train_cleaned[:, i]).sum() / x_train_cleaned.shape[0]\n",
    "    if missing_values > missing_values_threshold:\n",
    "        columns_to_drop.append(i)\n",
    "\n",
    "x_train_cleaned = np.delete(x_train_cleaned, columns_to_drop, axis=1)\n",
    "x_test_cleaned = np.delete(x_test_cleaned, columns_to_drop, axis=1)\n",
    "\n",
    "# Remove the same columns from the headers\n",
    "x_train_header_cleaned = [col for i, col in enumerate(x_train_header_cleaned) if i not in columns_to_drop]\n",
    "x_test_header_cleaned = [col for i, col in enumerate(x_test_header_cleaned) if i not in columns_to_drop]\n",
    "\n",
    "\n",
    "\n",
    "print(x_train_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 168)\n",
      "(109379, 168)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "general_health_column_index = x_train_header_cleaned.index(\"GENHLTH\")\n",
    "\n",
    "# Extract the \"General Health\" column\n",
    "gen_health_train = x_train_cleaned[:, general_health_column_index]\n",
    "gen_health_test = x_test_cleaned[:, general_health_column_index]\n",
    "\n",
    "# Function to create dummy variables for general health\n",
    "def create_gen_health_dummy_variables(health_column):\n",
    "    # Initialize dummy matrix (for values 1 to 5)\n",
    "    dummy_matrix = np.zeros((health_column.shape[0], 5))\n",
    "    \n",
    "    # Fill dummy variables based on the values in the column\n",
    "    for i in range(1, 6):  # For values 1 to 5\n",
    "        dummy_matrix[:, i-1] = (health_column == i).astype(int)\n",
    "    \n",
    "    # Values 7, 9, and nan are left as 0 in all dummies\n",
    "    return dummy_matrix\n",
    "\n",
    "# Create dummy variables for both train and test datasets\n",
    "dummy_train_gen_health = create_gen_health_dummy_variables(gen_health_train)\n",
    "dummy_test_gen_health = create_gen_health_dummy_variables(gen_health_test)\n",
    "\n",
    "# Remove the original \"General Health\" column from x_train_cleaned and x_test_cleaned\n",
    "x_train_cleaned = np.delete(x_train_cleaned, general_health_column_index, axis=1)\n",
    "x_test_cleaned = np.delete(x_test_cleaned, general_health_column_index, axis=1)\n",
    "\n",
    "# Append the dummy variables to the original dataset\n",
    "x_train_cleaned = np.hstack((x_train_cleaned, dummy_train_gen_health))\n",
    "x_test_cleaned = np.hstack((x_test_cleaned, dummy_test_gen_health))\n",
    "\n",
    "# Update the headers\n",
    "gen_health_dummy_headers = [f\"GENHLTH_{i}\" for i in range(1, 6)]\n",
    "x_train_header_cleaned = [col for col in x_train_header_cleaned if col != \"General Health\"] + gen_health_dummy_headers\n",
    "x_test_header_cleaned = [col for col in x_test_header_cleaned if col != \"General Health\"] + gen_health_dummy_headers\n",
    "\n",
    "\n",
    "# Check shapes after adding dummy variables\n",
    "print(x_train_cleaned.shape)\n",
    "print(x_test_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in columns PHYSHLTH, MENTHLTH and POORHLTH, make values 88 into 0, and values 77 and  99 into nan\n",
    "physhlth_column_index = x_train_header_cleaned.index(\"PHYSHLTH\")\n",
    "menthlth_column_index = x_train_header_cleaned.index(\"MENTHLTH\")\n",
    "poorhlth_column_index = x_train_header_cleaned.index(\"POORHLTH\")\n",
    "\n",
    "# Replace values in PHYSHLTH and MENTHLTH and POORHLTH columns\n",
    "x_train_cleaned[:, physhlth_column_index][x_train_cleaned[:, physhlth_column_index] == 88] = 0\n",
    "x_train_cleaned[:, physhlth_column_index][x_train_cleaned[:, physhlth_column_index] == 77] = np.nan\n",
    "x_train_cleaned[:, physhlth_column_index][x_train_cleaned[:, physhlth_column_index] == 99] = np.nan\n",
    "\n",
    "x_train_cleaned[:, menthlth_column_index][x_train_cleaned[:, menthlth_column_index] == 88] = 0\n",
    "x_train_cleaned[:, menthlth_column_index][x_train_cleaned[:, menthlth_column_index] == 77] = np.nan\n",
    "x_train_cleaned[:, menthlth_column_index][x_train_cleaned[:, menthlth_column_index] == 99] = np.nan\n",
    "\n",
    "x_train_cleaned[:, poorhlth_column_index][x_train_cleaned[:, poorhlth_column_index] == 88] = 0\n",
    "x_train_cleaned[:, poorhlth_column_index][x_train_cleaned[:, poorhlth_column_index] == 77] = np.nan\n",
    "x_train_cleaned[:, poorhlth_column_index][x_train_cleaned[:, poorhlth_column_index] == 99] = np.nan\n",
    "\n",
    "# Replace values in PHYSHLTH and MENTHLTH columns in test dataset\n",
    "x_test_cleaned[:, physhlth_column_index][x_test_cleaned[:, physhlth_column_index] == 88] = 0\n",
    "x_test_cleaned[:, physhlth_column_index][x_test_cleaned[:, physhlth_column_index] == 77] = np.nan\n",
    "x_test_cleaned[:, physhlth_column_index][x_test_cleaned[:, physhlth_column_index] == 99] = np.nan\n",
    "\n",
    "x_test_cleaned[:, menthlth_column_index][x_test_cleaned[:, menthlth_column_index] == 88] = 0\n",
    "x_test_cleaned[:, menthlth_column_index][x_test_cleaned[:, menthlth_column_index] == 77] = np.nan\n",
    "x_test_cleaned[:, menthlth_column_index][x_test_cleaned[:, menthlth_column_index] == 99] = np.nan\n",
    "\n",
    "x_test_cleaned[:, poorhlth_column_index][x_test_cleaned[:, poorhlth_column_index] == 88] = 0\n",
    "x_test_cleaned[:, poorhlth_column_index][x_test_cleaned[:, poorhlth_column_index] == 77] = np.nan\n",
    "x_test_cleaned[:, poorhlth_column_index][x_test_cleaned[:, poorhlth_column_index] == 99] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 184)\n",
      "(109379, 168)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# List of columns to process\n",
    "columns_to_process = [\n",
    "    'HLTHPLN1', 'PERSDOC2', 'MEDCOST', 'CHECKUP1',\n",
    "    'BPHIGH4', 'BLOODCHO', 'CHOLCHK', 'TOLDHI2'\n",
    "]\n",
    "\n",
    "# Collect unique values from both datasets to ensure consistency\n",
    "unique_values_dict = {}\n",
    "for column_name in columns_to_process:\n",
    "    # Get indices of the column in train and test headers\n",
    "    idx_train = x_train_header_cleaned.index(column_name)\n",
    "    idx_test = x_test_header_cleaned.index(column_name)\n",
    "    \n",
    "    # Extract column data\n",
    "    column_train = x_train_cleaned[:, idx_train]\n",
    "    column_test = x_test_cleaned[:, idx_test]\n",
    "    \n",
    "    # Replace 7, 9, and BLANK (np.nan) with 0\n",
    "    column_train = np.where(np.isin(column_train, [7, 9]) | np.isnan(column_train), 0, column_train)\n",
    "    column_test = np.where(np.isin(column_test, [7, 9]) | np.isnan(column_test), 0, column_test)\n",
    "    \n",
    "    # Get unique values excluding 0\n",
    "    unique_values = np.unique(np.concatenate((column_train, column_test)))\n",
    "    unique_values = unique_values[unique_values != 0]\n",
    "    \n",
    "    unique_values_dict[column_name] = unique_values\n",
    "\n",
    "def create_dummy_variables_for_column(data, headers, column_name, unique_values):\n",
    "    # Find the index of the column\n",
    "    idx = headers.index(column_name)\n",
    "    # Extract the column data\n",
    "    column_data = data[:, idx]\n",
    "    \n",
    "    # Replace 7, 9, and BLANK (np.nan) with 0\n",
    "    column_data = np.where(np.isin(column_data, [7, 9]) | np.isnan(column_data), 0, column_data)\n",
    "    \n",
    "    # Remove the original column\n",
    "    data = np.delete(data, idx, axis=1)\n",
    "    del headers[idx]\n",
    "    \n",
    "    # Create dummy variables for each unique value (excluding 0)\n",
    "    for val in unique_values:\n",
    "        dummy_column = np.where(column_data == val, 1, 0)\n",
    "        data = np.column_stack((data, dummy_column))\n",
    "        headers.append(f\"{column_name}_{int(val)}\")\n",
    "    \n",
    "    return data, headers\n",
    "\n",
    "def process_dataset(data, headers, unique_values_dict):\n",
    "    # Make copies to avoid modifying the original data\n",
    "    data = data.copy()\n",
    "    headers = headers.copy()\n",
    "    \n",
    "    for column_name in columns_to_process:\n",
    "        data, headers = create_dummy_variables_for_column(\n",
    "            data, headers, column_name, unique_values_dict[column_name]\n",
    "        )\n",
    "    return data, headers\n",
    "\n",
    "# Process x_train_cleaned\n",
    "x_train_cleaned_processed, x_train_header_cleaned_processed = process_dataset(\n",
    "    x_train_cleaned, x_train_header_cleaned, unique_values_dict\n",
    ")\n",
    "\n",
    "# Process x_test_cleaned\n",
    "x_test_cleaned_processed, x_test_header_cleaned_processed = process_dataset(\n",
    "    x_test_cleaned, x_test_header_cleaned, unique_values_dict\n",
    ")\n",
    "\n",
    "\n",
    "print(x_train_cleaned_processed.shape)\n",
    "print(x_test_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data with headers\n",
    "with open('dataset/x_train_cleaned.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(x_train_header_cleaned_processed)\n",
    "    writer.writerows(x_train_cleaned_processed)\n",
    "\n",
    "with open('dataset/x_test_cleaned.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(x_test_header_cleaned_processed)\n",
    "    writer.writerows(x_test_cleaned_processed)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
